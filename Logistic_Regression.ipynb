{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic_Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ruchirgavshinde/machinelearninglab-CS-3-acro/blob/master/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9qBjoWDJVNN",
        "colab_type": "code",
        "outputId": "477dbc16-82c7-4707-e02d-b5c5ef06735b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "import csv \n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "  \n",
        "  \n",
        "def loadCSV(filename): \n",
        "    with open(filename,\"r\") as csvfile: \n",
        "      lines = csv.reader(csvfile) \n",
        "      dataset = list(lines) \n",
        "      for i in range(len(dataset)): \n",
        "        dataset[i] = [float(x) for x in dataset[i]]      \n",
        "    return np.array(dataset) \n",
        "  \n",
        "  \n",
        "def normalize(X): \n",
        "     \n",
        "    mins = np.min(X, axis = 0) \n",
        "    maxs = np.max(X, axis = 0) \n",
        "    rng = maxs - mins \n",
        "    norm_X = 1 - ((maxs - X)/rng)\n",
        "    print(X)\n",
        "    return norm_X \n",
        "    \n",
        "  \n",
        "def logistic_func(beta, X): \n",
        "    \n",
        "    # below is the code for 1/1+e^(-(bo*x1+ b1*x2 +  b1*x3............ ))\n",
        "    #return  horizontal array\n",
        "    return 1.0/(1 + np.exp(-np.dot(X, beta.T))) \n",
        "  \n",
        "  \n",
        "def log_gradient(beta, X, y): \n",
        "     \n",
        "   \n",
        "    #first_calc = y_prediction - y_actual  for all samples # make y_actual as\n",
        "    first_calc = logistic_func(beta, X) - y.reshape(X.shape[0], -1) \n",
        "    # now in below step we will find the partial derivative\n",
        "    #final_calc= gradient is (y_prediction - y_actual)*x  for all samples \n",
        "    final_calc = np.dot(first_calc.T, X) \n",
        "    \n",
        "    return final_calc \n",
        "  \n",
        "  \n",
        "def cost_func(beta, X, y): \n",
        "    \n",
        "   \n",
        "    \n",
        "    #y_prediction=  1/1+e^(-(bo*x1+ b1*x2 +  b1*x3............ )) for all samples\n",
        "    y_prediction= logistic_func(beta, X) \n",
        "    y = np.squeeze(y) \n",
        "    # calculate cross entropy cost function for all samples\n",
        "    cost_function = -(y * np.log(y_prediction)) - ((1 - y) * np.log(1 - y_prediction) ) \n",
        "    # return the sum of  cost function divided by no. of samples\n",
        "    return np.mean(cost_function) \n",
        "  \n",
        "  \n",
        "def train(X, y, beta, lr=.01, converge_change=.001): \n",
        "     \n",
        "    \n",
        "    \n",
        "    cost = cost_func(beta, X, y) \n",
        "    change_cost = 1\n",
        "    num_iter = 1\n",
        "      \n",
        "    while(change_cost > converge_change): \n",
        "        old_cost = cost \n",
        "        #beta= beta - learning_rate * partial derivative of cost function w.r.t beta\n",
        "        beta = beta - (lr * log_gradient(beta, X, y)) \n",
        "        # again calculate cost function\n",
        "        cost = cost_func(beta, X, y) \n",
        "        # find difference between old cost and new cost \n",
        "        #if change is greater than .001 then reiterate \n",
        "        change_cost = old_cost - cost \n",
        "        num_iter += 1\n",
        "      \n",
        "    return beta, num_iter  \n",
        "  \n",
        "  \n",
        "def pred_values(beta, X): \n",
        "    \n",
        "    \n",
        "    \n",
        "    pred_prob = logistic_func(beta, X) \n",
        "    pred_value = np.where(pred_prob >= .5, 1, 0) \n",
        "    return np.squeeze(pred_value) \n",
        "  \n",
        "  \n",
        "def plot_reg(X, y, beta): \n",
        "    \n",
        "   \n",
        "    # labelled observations \n",
        "    x_0 = X[np.where(y == 0.0)] \n",
        "    x_1 = X[np.where(y == 1.0)] \n",
        "      \n",
        "    # plotting points with diff color for diff label \n",
        "    plt.scatter([x_0[:, 1]], [x_0[:, 2]], c='b', label='y = 0') \n",
        "    plt.scatter([x_1[:, 1]], [x_1[:, 2]], c='r', label='y = 1') \n",
        "      \n",
        "    # plotting decision boundary \n",
        "    x1 = np.arange(0, 1, 0.1) \n",
        "    x2 = -(beta[0,0] + beta[0,1]*x1)/beta[0,2] \n",
        "    plt.plot(x1, x2, c='k', label='reg line') \n",
        "  \n",
        "    plt.xlabel('x1') \n",
        "    plt.ylabel('x2') \n",
        "    plt.legend() \n",
        "    plt.show() \n",
        "      \n",
        "  \n",
        "      \n",
        "if __name__ == \"__main__\": \n",
        "    # load the dataset \n",
        "    dataset = loadCSV('dataset1.csv') \n",
        "      \n",
        "    # normalizing feature matrix \n",
        "    X = normalize(dataset[:, :-1]) \n",
        "    print(X)\n",
        "      \n",
        "    # stacking columns wth all ones in feature matrix \n",
        "    X = np.hstack((np.matrix(np.ones(X.shape[0])).T, X))\n",
        "    print(X)\n",
        "  \n",
        "    # response vector \n",
        "    y = dataset[:, -1] \n",
        "  \n",
        "    # initial beta values \n",
        "    beta = np.matrix(np.zeros(X.shape[1])) \n",
        "  \n",
        "    # beta values after running gradient descent \n",
        "    beta, num_iter =train(X, y, beta) \n",
        "  \n",
        "    # estimated beta values and number of iterations \n",
        "    print(\"Estimated regression coefficients:\", beta) \n",
        "    print(\"No. of iterations:\", num_iter) \n",
        "    # predicted labels \n",
        "    y_pred = pred_values(beta, X) \n",
        "      \n",
        "    # number of correctly predicted labels \n",
        "    print(\"Correctly predicted labels:\", np.sum(y == y_pred)) \n",
        "      \n",
        "    # plotting regression line \n",
        "    plot_reg(X, y, beta) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-1a090662d60a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# load the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dataset1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;31m# normalizing feature matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-1a090662d60a>\u001b[0m in \u001b[0;36mloadCSV\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mloadCSV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcsvfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'dataset1.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJFLlHqgnSyx",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    }
  ]
}